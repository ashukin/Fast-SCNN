{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "F-SCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3gGnUGUlNxuC",
        "colab": {}
      },
      "source": [
        "\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JQKNSAeyN0Xe",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jqz_r9wqO6yB",
        "outputId": "0b40251d-917f-45ca-c434-4aca5a4f027f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive');"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aDxpUxsLPCWA",
        "colab": {}
      },
      "source": [
        "# Import train, validation and test images from the folders and store in a list\n",
        "\n",
        "import os\n",
        "\n",
        "# To load images\n",
        "\n",
        "def load_img(folder):\n",
        "    c = 0;\n",
        "    images = [];\n",
        "    for filename in os.listdir(folder): # List all the filenames in the folder\n",
        "        c = c + 1;\n",
        "        print(c);\n",
        "        img = cv2.imread(os.path.join(folder, filename)); # Join the link of the folder and filename\n",
        "        img = cv2.resize(img, (128, 128), interpolation = cv2.INTER_AREA);\n",
        "        images.append(img);\n",
        "    return images\n",
        "\n",
        "# To load labeled gray-scaled images\n",
        "\n",
        "def load_label_img(folder):\n",
        "    images = [];\n",
        "    c = 0;\n",
        "    for filename in os.listdir(folder): # List all the filenames in the folder\n",
        "        c = c + 1;\n",
        "        print(c);\n",
        "        img = cv2.imread(os.path.join(folder, filename)); # Join the link of the folder and filename\n",
        "        img = cv2.resize(img, (128, 128), interpolation = cv2.INTER_AREA);\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY);\n",
        "        images.append(img);\n",
        "    return images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QLfYSFTdPg0a",
        "colab": {}
      },
      "source": [
        "# Convert the output labels to pixel-wise classes\n",
        "\n",
        "def c2g(cn):\n",
        "    cn = np.reshape(cn, (1, 1, 3));\n",
        "    cn = cv2.cvtColor(cn, cv2.COLOR_BGR2GRAY);\n",
        "    return cn;\n",
        "\n",
        "colors = [];\n",
        "colors.append(c2g(np.array([64, 128, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 0, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 128, 0], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 128, 0], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([0, 0, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 0, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 0, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 128, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 192, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 64, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 0, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 0, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 128, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 0, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 64, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 192, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([0, 64, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 64, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 128, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 0, 0], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 128, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 128, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 128, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 0, 0], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 64, 0], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([128, 64, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([0, 128, 128], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([192, 128, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([64, 0, 64], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([0, 192, 192], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([0, 0, 0], dtype = 'uint8')));\n",
        "colors.append(c2g(np.array([0, 192, 64], dtype = 'uint8')));\n",
        "\n",
        "# c0 = np.reshape(np.array([64, 128, 0], dtype = 'uint8'), (1, 1, 3)); # opencv supports uint8 and not int32/int64\n",
        "# c0 = cv2.cvtColor(c0, cv2.COLOR_BGR2GRAY)\n",
        "# print(c0)\n",
        "\n",
        "def class_pixel(label_img):\n",
        "    class_pix = np.ones([128, 128, 1], dtype = int);\n",
        "    for index, c in enumerate(colors):\n",
        "        class_pix[label_img == c] = index; # Vectorized masking is much much faster\n",
        "    return class_pix\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q0sMsuDBPmNN",
        "colab": {}
      },
      "source": [
        "# Convert all segmented images into labeled images\n",
        "\n",
        "def label_img_list(img_list):\n",
        "    images = [];\n",
        "    for image in img_list:\n",
        "        images.append(class_pixel(image));\n",
        "    return images;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lHRJG3PHPrAF",
        "outputId": "edfb0c0c-d8b9-44de-d303-c92d84b9551a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define the transformations that have to be applied on the images\n",
        "\n",
        "transform_img = transforms.Compose([ \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],   # input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
        "                        std=[0.5, 0.5, 0.5])]);\n",
        "\n",
        "transform_img_label = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "]);\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# We have to create custom classes in order to use the DataLoader. These classes inherit the Dataset class\n",
        "\n",
        "class trainset(data.Dataset):\n",
        "    def __init__(self, transform = None, root_train = None, root_train_label = None, transform_label = None):\n",
        "        self.train_img = load_img(root_train);\n",
        "        self.transform = transform;\n",
        "        self.transform_label = transform_label;\n",
        "        self.train_label_img = label_img_list(load_label_img(root_train_label));\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.train_img);\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = self.transform(self.train_img[index]);\n",
        "        label = self.transform_label(self.train_label_img[index]);\n",
        "        return img, label;\n",
        "\n",
        "class valset(data.Dataset):\n",
        "    def __init__(self, transform = None, root_val = None, root_val_label = None, transform_label = None):\n",
        "        self.val_img = load_img(root_val);\n",
        "        self.transform = transform;\n",
        "        self.transform_label = transform_label;\n",
        "        self.val_label_img = label_img_list(load_label_img(root_val_label));\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.val_img);\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = self.transform(self.val_img[index]);\n",
        "        label = self.transform_label(self.val_label_img[index]);\n",
        "        return img, label;\n",
        "\n",
        "    \n",
        "class testset(data.Dataset):\n",
        "    def __init__(self, transform = None, root_test = None, root_test_label = None, transform_label = None):\n",
        "        self.test_img = load_img(root_test);\n",
        "        self.transform = transform;\n",
        "        self.transform_label = transform_label;\n",
        "        self.test_label_img = label_img_list(load_label_img(root_test_label));\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.test_img);\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = self.transform(self.test_img[index]);\n",
        "        label = self.transform_label(self.test_label_img[index]);\n",
        "        return img, label;\n",
        "\n",
        "\n",
        "traindataset = trainset(transform_img, '/content/gdrive/My Drive/Camvid dataset/train/', '/content/gdrive/My Drive/Camvid dataset/train_labels/', transform_img_label);\n",
        "# valdataset = valset(transform_img, '/content/gdrive/My Drive/Camvid dataset/val/', '/content/gdrive/My Drive/Camvid dataset/val_labels/', transform_img_label);\n",
        "testdataset = testset(transform_img, '/content/gdrive/My Drive/Camvid dataset/test/', '/content/gdrive/My Drive/Camvid dataset/test_labels/', transform_img_label);\n",
        "\n",
        "# We have to instantiate these classes and feed this to the dataloader"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XOl8sxAxIMa3",
        "colab": {}
      },
      "source": [
        "train_loader = data.DataLoader(traindataset, batch_size = 1, shuffle=True,  num_workers=4);\n",
        "# val_loader = data.DataLoader(valdataset, batch_size = 32, shuffle=True,  num_workers=4);\n",
        "test_loader = data.DataLoader(testdataset, batch_size = 1, shuffle=True,  num_workers=4);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mHi1BGUiIQIZ",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class Fast_SCNN(torch.nn.Module):\n",
        "    def __init__(self, input_channel, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.learning_to_downsample = LearningToDownsample(input_channel)\n",
        "        self.global_feature_extractor = GlobalFeatureExtractor()\n",
        "        self.feature_fusion = FeatureFusionModule()\n",
        "        self.classifier = Classifier(num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('before everything size = ', x.size())\n",
        "        shared = self.learning_to_downsample(x)\n",
        "        #print('After learning_to ds size of o/p = ',shared.size())\n",
        "        x = self.global_feature_extractor(shared)\n",
        "        #print('After global_feat extr size of o/p = ',x.size())\n",
        "        x = self.feature_fusion(shared, x)\n",
        "        #print('After feat fusion size of o/p = ',x.size())\n",
        "        x = self.classifier(x)\n",
        "        #print('After classifier i.e. finally size of o/p = ',x.size())\n",
        "        torch.nn.Dropout(0.3)\n",
        "        x = F.interpolate(input= x, scale_factor=8, mode='bilinear', align_corners=True)\n",
        "        #print('Finally???????',x.size())\n",
        "        return x\n",
        "\n",
        "\n",
        "class LearningToDownsample(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=32, stride=2)\n",
        "        self.sconv1 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1, dilation=1, groups=32, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 48, kernel_size=1, stride=1, padding=0, dilation=1, groups=1, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True))\n",
        "        self.sconv2 = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, kernel_size=3, stride=2, padding=1, dilation=1, groups=48, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.Conv2d(48, 64, kernel_size=1, stride=1, padding=0, dilation=1, groups=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.sconv1(x)\n",
        "        x = self.sconv2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GlobalFeatureExtractor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.first_block = nn.Sequential(InvertedResidual(64, 64, 2, 6),\n",
        "                                         InvertedResidual(64, 64, 1, 6),\n",
        "                                         InvertedResidual(64, 64, 1, 6))\n",
        "        self.second_block = nn.Sequential(InvertedResidual(64, 96, 2, 6),\n",
        "                                          InvertedResidual(96, 96, 1, 6),\n",
        "                                          InvertedResidual(96, 96, 1, 6))\n",
        "        self.third_block = nn.Sequential(InvertedResidual(96, 128, 1, 6),\n",
        "                                         InvertedResidual(128, 128, 1, 6),\n",
        "                                         InvertedResidual(128, 128, 1, 6))\n",
        "        self.ppm = PSPModule(128, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first_block(x)\n",
        "        x = self.second_block(x)\n",
        "        x = self.third_block(x)\n",
        "        x = self.ppm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Modified from https://github.com/tonylins/pytorch-mobilenet-v2\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = round(inp * expand_ratio)\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        if expand_ratio == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "# Modified from https://github.com/Lextal/pspnet-pytorch/blob/master/pspnet.py\n",
        "class PSPModule(nn.Module):\n",
        "    def __init__(self, features, out_features=1024, sizes=(1, 2, 3, 6)):\n",
        "        super().__init__()\n",
        "        self.stages = []\n",
        "        self.stages = nn.ModuleList([self._make_stage(features, size) for size in sizes])\n",
        "        self.bottleneck = nn.Conv2d(features * (len(sizes) + 1), out_features, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def _make_stage(self, features, size):\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
        "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
        "        return nn.Sequential(prior, conv)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        h, w = feats.size(2), feats.size(3)\n",
        "        priors = [F.interpolate(input=stage(feats), size=(h,w), mode='bilinear',\n",
        "                                align_corners=True) for stage in self.stages] + [feats]\n",
        "        # import pdb;pdb.set_trace()\n",
        "        bottle = self.bottleneck(torch.cat(priors, 1))\n",
        "        return self.relu(bottle)\n",
        "\n",
        "\n",
        "class FeatureFusionModule(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sconv1 = ConvBlock(in_channels=128, out_channels=128, stride=1, dilation=1, groups=128)\n",
        "        self.conv_low_res = nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "        self.conv_high_res = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, high_res_input, low_res_input):\n",
        "        low_res_input = F.interpolate(input=low_res_input, scale_factor=4, mode='bilinear', align_corners=True)\n",
        "        low_res_input = self.sconv1(low_res_input)\n",
        "        low_res_input = self.conv_low_res(low_res_input)\n",
        "\n",
        "        high_res_input = self.conv_high_res(high_res_input)\n",
        "        x = torch.add(high_res_input, low_res_input)\n",
        "        return self.relu(x)\n",
        "\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.sconv1 = ConvBlock(in_channels=128, out_channels=128, stride=1, dilation=1, groups=128)\n",
        "        self.sconv2 = ConvBlock(in_channels=128, out_channels=128, stride=1, dilation=1, groups=128)\n",
        "        self.conv = nn.Conv2d(128, num_classes, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sconv1(x)\n",
        "        x = self.sconv1(x)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class ConvBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, dilation=1, groups=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                               dilation=dilation, groups=groups, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        return self.relu(self.bn(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HAcRwE_PQJYq",
        "outputId": "6ab418bd-0312-4d42-a4ed-b44cf8d23356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
        "print(device)\n",
        "UNET = Fast_SCNN(input_channel=3, num_classes=32);\n",
        "UNET.to(device);\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZDBnT5Z2QTwP",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = optim.Adam(UNET.parameters(), lr = 0.0001, betas = (0.9, 0.999), eps = 1e-08, weight_decay=0, amsgrad=False);\n",
        "\n",
        "# # Loading the data\n",
        "# PATH = '/content/gdrive/My Drive/Camvid dataset/saved.pth';\n",
        "# UNET.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5tg5vqBQa3p",
        "outputId": "e472c2af-c7cd-44b7-9960-78f8dc65835b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(50):\n",
        "  for i, data in enumerate(train_loader):  \n",
        "    inputs, labels = data;\n",
        "    # print(np.shape(inputs))\n",
        "    # print(np.shape(labels))\n",
        "    if labels.size() == torch.Size([1, 1, 128, 128]):\n",
        "      labels = labels.reshape(1, 128, 128);\n",
        "    elif labels.size() == torch.Size([4, 1, 128, 128]):\n",
        "      labels = labels.reshape(4, 128, 128);\n",
        "    inputs, labels = inputs.to(device), labels.to(device);\n",
        "    optimizer.zero_grad();\n",
        "    outputs = UNET(inputs);\n",
        "    loss = criterion(outputs, labels);\n",
        "    loss.backward();\n",
        "    optimizer.step();\n",
        "    print(loss.item());\n",
        "    if loss.item() < 0.6:\n",
        "      break;\n",
        " "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8167549967765808\n",
            "0.6454095840454102\n",
            "0.974348247051239\n",
            "0.905590832233429\n",
            "0.8539328575134277\n",
            "0.8477686643600464\n",
            "0.5761151313781738\n",
            "0.9264551401138306\n",
            "0.696945309638977\n",
            "0.752857506275177\n",
            "0.611678957939148\n",
            "0.948907196521759\n",
            "0.5847488045692444\n",
            "0.8764914274215698\n",
            "1.0221006870269775\n",
            "0.8129697442054749\n",
            "0.7696908116340637\n",
            "0.964942216873169\n",
            "0.9467933773994446\n",
            "1.0156193971633911\n",
            "1.2026100158691406\n",
            "0.9378887414932251\n",
            "1.174749732017517\n",
            "0.7571024298667908\n",
            "0.985264778137207\n",
            "0.7520563006401062\n",
            "0.7370529770851135\n",
            "0.751350998878479\n",
            "0.8803220987319946\n",
            "0.8740152716636658\n",
            "0.5128459930419922\n",
            "0.8406236171722412\n",
            "1.070427417755127\n",
            "0.6755226254463196\n",
            "0.7535479068756104\n",
            "0.8955764770507812\n",
            "0.9498350024223328\n",
            "0.8477271795272827\n",
            "0.7189807295799255\n",
            "0.6509576439857483\n",
            "0.7442715167999268\n",
            "0.5932169556617737\n",
            "0.7287281155586243\n",
            "0.8636311888694763\n",
            "0.9247076511383057\n",
            "0.7669164538383484\n",
            "0.6760152578353882\n",
            "0.6466420888900757\n",
            "0.8428093194961548\n",
            "0.8249087333679199\n",
            "0.5675294995307922\n",
            "0.7522459030151367\n",
            "0.42048144340515137\n",
            "0.8973867893218994\n",
            "0.926378607749939\n",
            "0.9921392202377319\n",
            "0.7400579452514648\n",
            "0.9120286107063293\n",
            "0.8327459096908569\n",
            "2.2323317527770996\n",
            "0.8841640949249268\n",
            "0.8397322297096252\n",
            "0.6475332975387573\n",
            "0.9826233983039856\n",
            "0.8998533487319946\n",
            "0.9402942061424255\n",
            "0.8999577164649963\n",
            "0.5812257528305054\n",
            "1.1092784404754639\n",
            "1.019200086593628\n",
            "0.7022769451141357\n",
            "0.48513898253440857\n",
            "1.5327565670013428\n",
            "0.8100752830505371\n",
            "0.8992869853973389\n",
            "0.5066846013069153\n",
            "0.4684850871562958\n",
            "0.813282310962677\n",
            "1.017463207244873\n",
            "0.623499870300293\n",
            "0.43085476756095886\n",
            "0.7978447079658508\n",
            "0.5765036940574646\n",
            "1.2761847972869873\n",
            "0.6020028591156006\n",
            "1.1198546886444092\n",
            "0.9734370112419128\n",
            "0.9837507605552673\n",
            "0.6353625059127808\n",
            "1.1807814836502075\n",
            "0.8661566972732544\n",
            "0.9254190325737\n",
            "0.8324752449989319\n",
            "0.8291770219802856\n",
            "0.7474786639213562\n",
            "0.7276448011398315\n",
            "0.634752094745636\n",
            "0.9072973132133484\n",
            "0.6302944421768188\n",
            "1.035071849822998\n",
            "0.7027963995933533\n",
            "0.9487857222557068\n",
            "0.8125251531600952\n",
            "0.8222583532333374\n",
            "0.7753264904022217\n",
            "0.7392697930335999\n",
            "0.724824070930481\n",
            "0.8539057970046997\n",
            "0.6930133700370789\n",
            "0.6925972700119019\n",
            "0.8543767333030701\n",
            "0.9629814624786377\n",
            "0.7924442291259766\n",
            "0.6460647583007812\n",
            "0.5801061987876892\n",
            "0.8809462189674377\n",
            "0.5401570200920105\n",
            "0.4815523326396942\n",
            "0.6336783766746521\n",
            "0.5854482054710388\n",
            "0.7887524366378784\n",
            "1.2592847347259521\n",
            "0.7158369421958923\n",
            "0.6150494813919067\n",
            "0.6165262460708618\n",
            "1.5485703945159912\n",
            "0.9383887648582458\n",
            "0.7966966032981873\n",
            "0.7720839977264404\n",
            "0.6671801209449768\n",
            "0.8221646547317505\n",
            "0.6095259189605713\n",
            "0.7832037210464478\n",
            "1.0736520290374756\n",
            "0.9140856862068176\n",
            "0.9302572011947632\n",
            "0.7543458938598633\n",
            "0.8663069009780884\n",
            "0.6440511345863342\n",
            "0.7689741849899292\n",
            "0.5752726793289185\n",
            "0.7261277437210083\n",
            "0.679742693901062\n",
            "0.661008894443512\n",
            "0.808654248714447\n",
            "0.6755924820899963\n",
            "0.8191335797309875\n",
            "0.9242346286773682\n",
            "1.0093090534210205\n",
            "0.8759850859642029\n",
            "0.8938403725624084\n",
            "1.0293192863464355\n",
            "0.8682337999343872\n",
            "1.0051727294921875\n",
            "0.9158949255943298\n",
            "0.6232922673225403\n",
            "0.8365820646286011\n",
            "1.390291452407837\n",
            "0.5657369494438171\n",
            "1.309808373451233\n",
            "0.8646840453147888\n",
            "0.7008634209632874\n",
            "0.8713862299919128\n",
            "0.7147094011306763\n",
            "0.7806229591369629\n",
            "0.5398159623146057\n",
            "0.5748889446258545\n",
            "1.0754814147949219\n",
            "0.7973225116729736\n",
            "0.9061265587806702\n",
            "0.8328310251235962\n",
            "0.7205765247344971\n",
            "0.7440089583396912\n",
            "0.8895464539527893\n",
            "0.9036920666694641\n",
            "0.480148583650589\n",
            "0.9298653602600098\n",
            "0.8293856382369995\n",
            "0.8726750612258911\n",
            "0.6475434899330139\n",
            "0.7042401432991028\n",
            "0.5857455730438232\n",
            "0.6607136726379395\n",
            "0.9665539264678955\n",
            "0.7941702604293823\n",
            "0.7472518086433411\n",
            "0.8775388598442078\n",
            "0.77740877866745\n",
            "1.173322319984436\n",
            "1.0725409984588623\n",
            "0.9048794507980347\n",
            "0.8967254161834717\n",
            "0.7169590592384338\n",
            "0.8590234518051147\n",
            "1.0956847667694092\n",
            "1.9363490343093872\n",
            "0.7183067798614502\n",
            "0.5644593834877014\n",
            "0.9263768792152405\n",
            "0.7289195656776428\n",
            "0.7294431328773499\n",
            "0.6219949722290039\n",
            "0.6872597932815552\n",
            "0.7968515753746033\n",
            "0.7039408087730408\n",
            "1.2147866487503052\n",
            "0.9677472114562988\n",
            "0.7659276723861694\n",
            "0.9004330635070801\n",
            "1.0153825283050537\n",
            "0.5682711601257324\n",
            "0.7464722990989685\n",
            "0.8409447073936462\n",
            "0.861183762550354\n",
            "0.6952652335166931\n",
            "0.8360278010368347\n",
            "0.6882261633872986\n",
            "0.5895714163780212\n",
            "0.9274861812591553\n",
            "0.6098471283912659\n",
            "0.6944442987442017\n",
            "0.6910189390182495\n",
            "0.9165313243865967\n",
            "0.610287070274353\n",
            "0.9589560031890869\n",
            "0.9363903999328613\n",
            "0.9381560683250427\n",
            "0.6121688485145569\n",
            "0.6224709749221802\n",
            "0.7546311616897583\n",
            "0.8018372654914856\n",
            "0.8210098743438721\n",
            "0.7998865842819214\n",
            "0.574535608291626\n",
            "0.7168787121772766\n",
            "0.47670599818229675\n",
            "0.6516785621643066\n",
            "0.8313429355621338\n",
            "0.9832522869110107\n",
            "0.5848082900047302\n",
            "0.8305157423019409\n",
            "0.596645712852478\n",
            "0.9796810150146484\n",
            "0.5462221503257751\n",
            "0.9286535978317261\n",
            "0.9504882097244263\n",
            "0.7944324612617493\n",
            "0.7314767837524414\n",
            "0.6918255090713501\n",
            "0.7946019768714905\n",
            "0.6498544812202454\n",
            "0.598965048789978\n",
            "0.7215743660926819\n",
            "2.074648857116699\n",
            "0.7305774092674255\n",
            "0.6053321957588196\n",
            "1.062581181526184\n",
            "0.9659378528594971\n",
            "0.8578962683677673\n",
            "0.651870846748352\n",
            "0.5947468280792236\n",
            "0.8068689107894897\n",
            "0.6124305725097656\n",
            "1.1465871334075928\n",
            "0.771580696105957\n",
            "0.705542802810669\n",
            "0.552352786064148\n",
            "0.7161649465560913\n",
            "0.6864383816719055\n",
            "0.6658985614776611\n",
            "0.618126630783081\n",
            "0.9605666399002075\n",
            "1.077962040901184\n",
            "0.6781383156776428\n",
            "0.700729489326477\n",
            "0.643660843372345\n",
            "0.8464055061340332\n",
            "0.7737722396850586\n",
            "1.2011934518814087\n",
            "0.8513469696044922\n",
            "0.747565507888794\n",
            "0.8931159377098083\n",
            "0.9878513813018799\n",
            "0.93108069896698\n",
            "0.9148793816566467\n",
            "0.7844343781471252\n",
            "1.0650755167007446\n",
            "0.7767593264579773\n",
            "0.6964139938354492\n",
            "0.8889143466949463\n",
            "0.8198916912078857\n",
            "0.8903292417526245\n",
            "0.6476753950119019\n",
            "0.5424001216888428\n",
            "0.830359935760498\n",
            "1.293643832206726\n",
            "0.8656150102615356\n",
            "0.8854346871376038\n",
            "1.0535130500793457\n",
            "0.6276395916938782\n",
            "0.4805842638015747\n",
            "0.7349475026130676\n",
            "0.6599445343017578\n",
            "0.9045215249061584\n",
            "1.7499303817749023\n",
            "0.9999969601631165\n",
            "0.8508254885673523\n",
            "0.5991631150245667\n",
            "0.5631614327430725\n",
            "0.8545764088630676\n",
            "0.9029715061187744\n",
            "0.8535730838775635\n",
            "0.5308389067649841\n",
            "0.9043706059455872\n",
            "0.9606215953826904\n",
            "0.7869648337364197\n",
            "0.8483399748802185\n",
            "0.8161285519599915\n",
            "1.0193212032318115\n",
            "0.9116846919059753\n",
            "0.8561432957649231\n",
            "0.7536941766738892\n",
            "0.8259363770484924\n",
            "1.0134624242782593\n",
            "0.7471935153007507\n",
            "0.8236140608787537\n",
            "0.5153942108154297\n",
            "0.6273296475410461\n",
            "0.8487434983253479\n",
            "0.5006139278411865\n",
            "0.6665544509887695\n",
            "0.6871625781059265\n",
            "0.6613695025444031\n",
            "0.7650021314620972\n",
            "0.8394874334335327\n",
            "0.5795894861221313\n",
            "1.2335522174835205\n",
            "0.7190802097320557\n",
            "0.9287223815917969\n",
            "0.8464598059654236\n",
            "0.6991104483604431\n",
            "0.8186425566673279\n",
            "0.8266623020172119\n",
            "0.5047232508659363\n",
            "0.8818570375442505\n",
            "0.822018027305603\n",
            "1.0093477964401245\n",
            "1.0564110279083252\n",
            "1.2690048217773438\n",
            "0.7956449389457703\n",
            "0.7843635678291321\n",
            "0.6684435606002808\n",
            "0.7714576721191406\n",
            "0.7308686971664429\n",
            "0.9259026050567627\n",
            "0.7633577585220337\n",
            "0.6609087586402893\n",
            "0.6231604218482971\n",
            "1.0266666412353516\n",
            "0.5924059152603149\n",
            "0.8669451475143433\n",
            "1.1711076498031616\n",
            "0.6966326236724854\n",
            "0.6540262699127197\n",
            "0.7044812440872192\n",
            "0.6847257018089294\n",
            "0.758113443851471\n",
            "0.4136033058166504\n",
            "1.060376524925232\n",
            "0.8584238886833191\n",
            "0.9719539284706116\n",
            "0.8501073718070984\n",
            "1.1151151657104492\n",
            "0.8295836448669434\n",
            "0.925229012966156\n",
            "0.6199177503585815\n",
            "0.741996169090271\n",
            "0.9705127477645874\n",
            "0.8459068536758423\n",
            "0.7281214594841003\n",
            "1.0028226375579834\n",
            "0.7829088568687439\n",
            "0.7734814286231995\n",
            "0.8581058382987976\n",
            "0.753136396408081\n",
            "1.2552447319030762\n",
            "0.5950526595115662\n",
            "0.9037766456604004\n",
            "0.9203787446022034\n",
            "1.0126211643218994\n",
            "0.7584963440895081\n",
            "0.7742034792900085\n",
            "0.7715602517127991\n",
            "0.8089595437049866\n",
            "0.7326873540878296\n",
            "1.4648412466049194\n",
            "0.8172392249107361\n",
            "0.8810660243034363\n",
            "0.7352025508880615\n",
            "0.7544498443603516\n",
            "0.9596762657165527\n",
            "0.8634605407714844\n",
            "0.8075588941574097\n",
            "0.8857453465461731\n",
            "0.6358150243759155\n",
            "0.880598247051239\n",
            "0.7057968974113464\n",
            "0.7853907942771912\n",
            "0.8285847306251526\n",
            "0.7657351493835449\n",
            "0.7967749238014221\n",
            "0.577882707118988\n",
            "1.2016977071762085\n",
            "0.8295989632606506\n",
            "0.7193434238433838\n",
            "0.7773674726486206\n",
            "0.724046528339386\n",
            "0.5891659259796143\n",
            "1.4404598474502563\n",
            "0.6093074679374695\n",
            "0.9449396133422852\n",
            "0.8779953718185425\n",
            "1.1248853206634521\n",
            "0.6842712759971619\n",
            "1.1326912641525269\n",
            "0.5965915322303772\n",
            "0.9799302220344543\n",
            "0.9341089129447937\n",
            "1.0328294038772583\n",
            "0.6774978637695312\n",
            "0.7725521326065063\n",
            "0.7531368732452393\n",
            "0.5949636697769165\n",
            "0.8702120184898376\n",
            "0.792031466960907\n",
            "1.0831739902496338\n",
            "0.8582205176353455\n",
            "0.741632878780365\n",
            "0.926646888256073\n",
            "0.7213764786720276\n",
            "0.8456076383590698\n",
            "0.9475114941596985\n",
            "1.0041460990905762\n",
            "0.4943262040615082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7_axpSndQuHn",
        "colab": {}
      },
      "source": [
        "PATH = '/content/gdrive/My Drive/Camvid dataset/saved.pth';\n",
        "torch.save(UNET.state_dict(),PATH); # A state_dict is simply a Python dictionary \n",
        "# object that maps each layer to its parameter tensor. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJcDMKaMI-_-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "022209c9-abcc-41d5-b0cd-da9afdb65056"
      },
      "source": [
        "# Loading the data\n",
        "PATH = '/content/gdrive/My Drive/Camvid dataset/saved.pth';\n",
        "UNET.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-jfJ1vLmU5MH",
        "colab": {}
      },
      "source": [
        "def corr(x): # To get proper correspondence between the outputs and the labels\n",
        "    x = x.cpu();\n",
        "    x = x.detach().numpy(); # Detach() was used as one can't convert a pytorch tensor to a numpy array if\n",
        "    # required_grad is set True for that variable\n",
        "    x = x.argmax(axis = 1);\n",
        "    return x;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jg_r0yuTfKzH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3dbc0c1c-b6fc-4a5a-9c59-2146221ab5eb"
      },
      "source": [
        "# Compute test-set accuracy\n",
        "\n",
        "correct = 0;\n",
        "total = 0;\n",
        "for i, data in enumerate(train_loader):\n",
        "    print(i)\n",
        "    print(correct)\n",
        "    print(total)\n",
        "    inputs, labels = data;\n",
        "    inputs = inputs.to(device);\n",
        "    outputs = UNET.forward(inputs);\n",
        "    outputs = corr(outputs);\n",
        "    if labels.size() == torch.Size([1, 1, 128, 128]):\n",
        "      labels = labels.detach().numpy();\n",
        "      labels = labels.reshape(1, 128, 128);\n",
        "    # labels = labels.reshape(4, 512, 512);\n",
        "    outputs = outputs.reshape(1, 128, 128);\n",
        "    for i in range(128):\n",
        "      for j in range(128):\n",
        "        for k in range(1):\n",
        "          total = total + 1;\n",
        "          if outputs[k, i, j] == labels[k, i, j]:\n",
        "            correct = correct + 1;\n",
        "print(\"Hence, the test set accuracy is \", (correct/total) * 100);"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fe025175c50>>\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fe025175c50>>\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fe025175c50>>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fe025175c50>>\n",
            "    self._shutdown_workers()\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    w.join()\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "AssertionError: can only join a child process\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    w.join()\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "12885\n",
            "16384\n",
            "2\n",
            "24209\n",
            "32768\n",
            "3\n",
            "37540\n",
            "49152\n",
            "4\n",
            "48418\n",
            "65536\n",
            "5\n",
            "60508\n",
            "81920\n",
            "6\n",
            "74578\n",
            "98304\n",
            "7\n",
            "84642\n",
            "114688\n",
            "8\n",
            "95861\n",
            "131072\n",
            "9\n",
            "108713\n",
            "147456\n",
            "10\n",
            "119849\n",
            "163840\n",
            "11\n",
            "132628\n",
            "180224\n",
            "12\n",
            "146139\n",
            "196608\n",
            "13\n",
            "159861\n",
            "212992\n",
            "14\n",
            "171662\n",
            "229376\n",
            "15\n",
            "183786\n",
            "245760\n",
            "16\n",
            "195716\n",
            "262144\n",
            "17\n",
            "209314\n",
            "278528\n",
            "18\n",
            "223540\n",
            "294912\n",
            "19\n",
            "235476\n",
            "311296\n",
            "20\n",
            "248694\n",
            "327680\n",
            "21\n",
            "260647\n",
            "344064\n",
            "22\n",
            "272785\n",
            "360448\n",
            "23\n",
            "286775\n",
            "376832\n",
            "24\n",
            "298836\n",
            "393216\n",
            "25\n",
            "311705\n",
            "409600\n",
            "26\n",
            "325802\n",
            "425984\n",
            "27\n",
            "340352\n",
            "442368\n",
            "28\n",
            "353733\n",
            "458752\n",
            "29\n",
            "365976\n",
            "475136\n",
            "30\n",
            "377044\n",
            "491520\n",
            "31\n",
            "390861\n",
            "507904\n",
            "32\n",
            "402847\n",
            "524288\n",
            "33\n",
            "415153\n",
            "540672\n",
            "34\n",
            "426796\n",
            "557056\n",
            "35\n",
            "438611\n",
            "573440\n",
            "36\n",
            "451452\n",
            "589824\n",
            "37\n",
            "464757\n",
            "606208\n",
            "38\n",
            "477563\n",
            "622592\n",
            "39\n",
            "490022\n",
            "638976\n",
            "40\n",
            "503478\n",
            "655360\n",
            "41\n",
            "517092\n",
            "671744\n",
            "42\n",
            "528978\n",
            "688128\n",
            "43\n",
            "539864\n",
            "704512\n",
            "44\n",
            "553876\n",
            "720896\n",
            "45\n",
            "566359\n",
            "737280\n",
            "46\n",
            "579418\n",
            "753664\n",
            "47\n",
            "591002\n",
            "770048\n",
            "48\n",
            "603502\n",
            "786432\n",
            "49\n",
            "615378\n",
            "802816\n",
            "50\n",
            "625780\n",
            "819200\n",
            "51\n",
            "638497\n",
            "835584\n",
            "52\n",
            "650460\n",
            "851968\n",
            "53\n",
            "662308\n",
            "868352\n",
            "54\n",
            "676011\n",
            "884736\n",
            "55\n",
            "688997\n",
            "901120\n",
            "56\n",
            "701021\n",
            "917504\n",
            "57\n",
            "712223\n",
            "933888\n",
            "58\n",
            "724464\n",
            "950272\n",
            "59\n",
            "737066\n",
            "966656\n",
            "60\n",
            "748843\n",
            "983040\n",
            "61\n",
            "761806\n",
            "999424\n",
            "62\n",
            "773462\n",
            "1015808\n",
            "63\n",
            "786342\n",
            "1032192\n",
            "64\n",
            "799017\n",
            "1048576\n",
            "65\n",
            "811501\n",
            "1064960\n",
            "66\n",
            "823788\n",
            "1081344\n",
            "67\n",
            "836343\n",
            "1097728\n",
            "68\n",
            "849743\n",
            "1114112\n",
            "69\n",
            "861609\n",
            "1130496\n",
            "70\n",
            "873222\n",
            "1146880\n",
            "71\n",
            "884918\n",
            "1163264\n",
            "72\n",
            "897054\n",
            "1179648\n",
            "73\n",
            "909072\n",
            "1196032\n",
            "74\n",
            "919679\n",
            "1212416\n",
            "75\n",
            "927621\n",
            "1228800\n",
            "76\n",
            "940947\n",
            "1245184\n",
            "77\n",
            "949073\n",
            "1261568\n",
            "78\n",
            "961901\n",
            "1277952\n",
            "79\n",
            "973529\n",
            "1294336\n",
            "80\n",
            "986487\n",
            "1310720\n",
            "81\n",
            "999746\n",
            "1327104\n",
            "82\n",
            "1010950\n",
            "1343488\n",
            "83\n",
            "1023890\n",
            "1359872\n",
            "84\n",
            "1037239\n",
            "1376256\n",
            "85\n",
            "1049196\n",
            "1392640\n",
            "86\n",
            "1060958\n",
            "1409024\n",
            "87\n",
            "1074290\n",
            "1425408\n",
            "88\n",
            "1087887\n",
            "1441792\n",
            "89\n",
            "1101113\n",
            "1458176\n",
            "90\n",
            "1113377\n",
            "1474560\n",
            "91\n",
            "1126340\n",
            "1490944\n",
            "92\n",
            "1139180\n",
            "1507328\n",
            "93\n",
            "1152549\n",
            "1523712\n",
            "94\n",
            "1164135\n",
            "1540096\n",
            "95\n",
            "1177215\n",
            "1556480\n",
            "96\n",
            "1189404\n",
            "1572864\n",
            "97\n",
            "1201953\n",
            "1589248\n",
            "98\n",
            "1215722\n",
            "1605632\n",
            "99\n",
            "1228036\n",
            "1622016\n",
            "100\n",
            "1239883\n",
            "1638400\n",
            "101\n",
            "1251513\n",
            "1654784\n",
            "102\n",
            "1264048\n",
            "1671168\n",
            "103\n",
            "1277367\n",
            "1687552\n",
            "104\n",
            "1290138\n",
            "1703936\n",
            "105\n",
            "1302167\n",
            "1720320\n",
            "106\n",
            "1314617\n",
            "1736704\n",
            "107\n",
            "1326616\n",
            "1753088\n",
            "108\n",
            "1338161\n",
            "1769472\n",
            "109\n",
            "1349530\n",
            "1785856\n",
            "110\n",
            "1361114\n",
            "1802240\n",
            "111\n",
            "1372553\n",
            "1818624\n",
            "112\n",
            "1384285\n",
            "1835008\n",
            "113\n",
            "1395881\n",
            "1851392\n",
            "114\n",
            "1407861\n",
            "1867776\n",
            "115\n",
            "1420156\n",
            "1884160\n",
            "116\n",
            "1431932\n",
            "1900544\n",
            "117\n",
            "1445318\n",
            "1916928\n",
            "118\n",
            "1457745\n",
            "1933312\n",
            "119\n",
            "1470191\n",
            "1949696\n",
            "120\n",
            "1483978\n",
            "1966080\n",
            "121\n",
            "1494754\n",
            "1982464\n",
            "122\n",
            "1508545\n",
            "1998848\n",
            "123\n",
            "1520369\n",
            "2015232\n",
            "124\n",
            "1532609\n",
            "2031616\n",
            "125\n",
            "1543896\n",
            "2048000\n",
            "126\n",
            "1549532\n",
            "2064384\n",
            "127\n",
            "1562417\n",
            "2080768\n",
            "128\n",
            "1573770\n",
            "2097152\n",
            "129\n",
            "1586477\n",
            "2113536\n",
            "130\n",
            "1600279\n",
            "2129920\n",
            "131\n",
            "1612324\n",
            "2146304\n",
            "132\n",
            "1624671\n",
            "2162688\n",
            "133\n",
            "1636170\n",
            "2179072\n",
            "134\n",
            "1648658\n",
            "2195456\n",
            "135\n",
            "1663746\n",
            "2211840\n",
            "136\n",
            "1675651\n",
            "2228224\n",
            "137\n",
            "1689137\n",
            "2244608\n",
            "138\n",
            "1702550\n",
            "2260992\n",
            "139\n",
            "1715561\n",
            "2277376\n",
            "140\n",
            "1728943\n",
            "2293760\n",
            "141\n",
            "1742435\n",
            "2310144\n",
            "142\n",
            "1753538\n",
            "2326528\n",
            "143\n",
            "1766434\n",
            "2342912\n",
            "144\n",
            "1779640\n",
            "2359296\n",
            "145\n",
            "1790814\n",
            "2375680\n",
            "146\n",
            "1802309\n",
            "2392064\n",
            "147\n",
            "1811574\n",
            "2408448\n",
            "148\n",
            "1823164\n",
            "2424832\n",
            "149\n",
            "1836821\n",
            "2441216\n",
            "150\n",
            "1849037\n",
            "2457600\n",
            "151\n",
            "1860330\n",
            "2473984\n",
            "152\n",
            "1872506\n",
            "2490368\n",
            "153\n",
            "1883727\n",
            "2506752\n",
            "154\n",
            "1894006\n",
            "2523136\n",
            "155\n",
            "1907091\n",
            "2539520\n",
            "156\n",
            "1918106\n",
            "2555904\n",
            "157\n",
            "1930642\n",
            "2572288\n",
            "158\n",
            "1944155\n",
            "2588672\n",
            "159\n",
            "1956935\n",
            "2605056\n",
            "160\n",
            "1971431\n",
            "2621440\n",
            "161\n",
            "1985327\n",
            "2637824\n",
            "162\n",
            "1997167\n",
            "2654208\n",
            "163\n",
            "2009949\n",
            "2670592\n",
            "164\n",
            "2023078\n",
            "2686976\n",
            "165\n",
            "2035573\n",
            "2703360\n",
            "166\n",
            "2046791\n",
            "2719744\n",
            "167\n",
            "2059470\n",
            "2736128\n",
            "168\n",
            "2072832\n",
            "2752512\n",
            "169\n",
            "2083629\n",
            "2768896\n",
            "170\n",
            "2095923\n",
            "2785280\n",
            "171\n",
            "2108407\n",
            "2801664\n",
            "172\n",
            "2121409\n",
            "2818048\n",
            "173\n",
            "2134861\n",
            "2834432\n",
            "174\n",
            "2147429\n",
            "2850816\n",
            "175\n",
            "2158646\n",
            "2867200\n",
            "176\n",
            "2172123\n",
            "2883584\n",
            "177\n",
            "2184575\n",
            "2899968\n",
            "178\n",
            "2198013\n",
            "2916352\n",
            "179\n",
            "2211090\n",
            "2932736\n",
            "180\n",
            "2222771\n",
            "2949120\n",
            "181\n",
            "2234586\n",
            "2965504\n",
            "182\n",
            "2246896\n",
            "2981888\n",
            "183\n",
            "2259417\n",
            "2998272\n",
            "184\n",
            "2272541\n",
            "3014656\n",
            "185\n",
            "2284264\n",
            "3031040\n",
            "186\n",
            "2297131\n",
            "3047424\n",
            "187\n",
            "2309741\n",
            "3063808\n",
            "188\n",
            "2319573\n",
            "3080192\n",
            "189\n",
            "2332830\n",
            "3096576\n",
            "190\n",
            "2346250\n",
            "3112960\n",
            "191\n",
            "2358229\n",
            "3129344\n",
            "192\n",
            "2370511\n",
            "3145728\n",
            "193\n",
            "2382738\n",
            "3162112\n",
            "194\n",
            "2394020\n",
            "3178496\n",
            "195\n",
            "2406370\n",
            "3194880\n",
            "196\n",
            "2418686\n",
            "3211264\n",
            "197\n",
            "2430351\n",
            "3227648\n",
            "198\n",
            "2439513\n",
            "3244032\n",
            "199\n",
            "2450610\n",
            "3260416\n",
            "200\n",
            "2462012\n",
            "3276800\n",
            "201\n",
            "2475600\n",
            "3293184\n",
            "202\n",
            "2485678\n",
            "3309568\n",
            "203\n",
            "2499252\n",
            "3325952\n",
            "204\n",
            "2512870\n",
            "3342336\n",
            "205\n",
            "2524825\n",
            "3358720\n",
            "206\n",
            "2537335\n",
            "3375104\n",
            "207\n",
            "2550248\n",
            "3391488\n",
            "208\n",
            "2563213\n",
            "3407872\n",
            "209\n",
            "2575271\n",
            "3424256\n",
            "210\n",
            "2588265\n",
            "3440640\n",
            "211\n",
            "2600405\n",
            "3457024\n",
            "212\n",
            "2613864\n",
            "3473408\n",
            "213\n",
            "2626938\n",
            "3489792\n",
            "214\n",
            "2639289\n",
            "3506176\n",
            "215\n",
            "2652635\n",
            "3522560\n",
            "216\n",
            "2665811\n",
            "3538944\n",
            "217\n",
            "2678134\n",
            "3555328\n",
            "218\n",
            "2691104\n",
            "3571712\n",
            "219\n",
            "2704606\n",
            "3588096\n",
            "220\n",
            "2718423\n",
            "3604480\n",
            "221\n",
            "2730253\n",
            "3620864\n",
            "222\n",
            "2741835\n",
            "3637248\n",
            "223\n",
            "2754536\n",
            "3653632\n",
            "224\n",
            "2764940\n",
            "3670016\n",
            "225\n",
            "2776337\n",
            "3686400\n",
            "226\n",
            "2787666\n",
            "3702784\n",
            "227\n",
            "2801641\n",
            "3719168\n",
            "228\n",
            "2813000\n",
            "3735552\n",
            "229\n",
            "2826739\n",
            "3751936\n",
            "230\n",
            "2839490\n",
            "3768320\n",
            "231\n",
            "2850060\n",
            "3784704\n",
            "232\n",
            "2862412\n",
            "3801088\n",
            "233\n",
            "2872726\n",
            "3817472\n",
            "234\n",
            "2883842\n",
            "3833856\n",
            "235\n",
            "2892172\n",
            "3850240\n",
            "236\n",
            "2904456\n",
            "3866624\n",
            "237\n",
            "2918366\n",
            "3883008\n",
            "238\n",
            "2930221\n",
            "3899392\n",
            "239\n",
            "2943924\n",
            "3915776\n",
            "240\n",
            "2953986\n",
            "3932160\n",
            "241\n",
            "2967906\n",
            "3948544\n",
            "242\n",
            "2980160\n",
            "3964928\n",
            "243\n",
            "2989985\n",
            "3981312\n",
            "244\n",
            "3003013\n",
            "3997696\n",
            "245\n",
            "3014912\n",
            "4014080\n",
            "246\n",
            "3027762\n",
            "4030464\n",
            "247\n",
            "3041163\n",
            "4046848\n",
            "248\n",
            "3053740\n",
            "4063232\n",
            "249\n",
            "3066327\n",
            "4079616\n",
            "250\n",
            "3078583\n",
            "4096000\n",
            "251\n",
            "3091684\n",
            "4112384\n",
            "252\n",
            "3102663\n",
            "4128768\n",
            "253\n",
            "3116226\n",
            "4145152\n",
            "254\n",
            "3128200\n",
            "4161536\n",
            "255\n",
            "3140248\n",
            "4177920\n",
            "256\n",
            "3151812\n",
            "4194304\n",
            "257\n",
            "3163402\n",
            "4210688\n",
            "258\n",
            "3174541\n",
            "4227072\n",
            "259\n",
            "3186610\n",
            "4243456\n",
            "260\n",
            "3199402\n",
            "4259840\n",
            "261\n",
            "3212880\n",
            "4276224\n",
            "262\n",
            "3224189\n",
            "4292608\n",
            "263\n",
            "3236485\n",
            "4308992\n",
            "264\n",
            "3249596\n",
            "4325376\n",
            "265\n",
            "3263383\n",
            "4341760\n",
            "266\n",
            "3276667\n",
            "4358144\n",
            "267\n",
            "3288261\n",
            "4374528\n",
            "268\n",
            "3301457\n",
            "4390912\n",
            "269\n",
            "3313856\n",
            "4407296\n",
            "270\n",
            "3326648\n",
            "4423680\n",
            "271\n",
            "3337209\n",
            "4440064\n",
            "272\n",
            "3350956\n",
            "4456448\n",
            "273\n",
            "3363522\n",
            "4472832\n",
            "274\n",
            "3376819\n",
            "4489216\n",
            "275\n",
            "3389533\n",
            "4505600\n",
            "276\n",
            "3401282\n",
            "4521984\n",
            "277\n",
            "3411160\n",
            "4538368\n",
            "278\n",
            "3424423\n",
            "4554752\n",
            "279\n",
            "3435606\n",
            "4571136\n",
            "280\n",
            "3445932\n",
            "4587520\n",
            "281\n",
            "3457672\n",
            "4603904\n",
            "282\n",
            "3470077\n",
            "4620288\n",
            "283\n",
            "3481944\n",
            "4636672\n",
            "284\n",
            "3494391\n",
            "4653056\n",
            "285\n",
            "3506184\n",
            "4669440\n",
            "286\n",
            "3518865\n",
            "4685824\n",
            "287\n",
            "3531378\n",
            "4702208\n",
            "288\n",
            "3541751\n",
            "4718592\n",
            "289\n",
            "3554550\n",
            "4734976\n",
            "290\n",
            "3568668\n",
            "4751360\n",
            "291\n",
            "3582179\n",
            "4767744\n",
            "292\n",
            "3595174\n",
            "4784128\n",
            "293\n",
            "3608707\n",
            "4800512\n",
            "294\n",
            "3621559\n",
            "4816896\n",
            "295\n",
            "3635258\n",
            "4833280\n",
            "296\n",
            "3645880\n",
            "4849664\n",
            "297\n",
            "3657611\n",
            "4866048\n",
            "298\n",
            "3669893\n",
            "4882432\n",
            "299\n",
            "3681099\n",
            "4898816\n",
            "300\n",
            "3693669\n",
            "4915200\n",
            "301\n",
            "3706432\n",
            "4931584\n",
            "302\n",
            "3719424\n",
            "4947968\n",
            "303\n",
            "3732847\n",
            "4964352\n",
            "304\n",
            "3745662\n",
            "4980736\n",
            "305\n",
            "3756868\n",
            "4997120\n",
            "306\n",
            "3768811\n",
            "5013504\n",
            "307\n",
            "3782565\n",
            "5029888\n",
            "308\n",
            "3794910\n",
            "5046272\n",
            "309\n",
            "3807479\n",
            "5062656\n",
            "310\n",
            "3820486\n",
            "5079040\n",
            "311\n",
            "3833194\n",
            "5095424\n",
            "312\n",
            "3844858\n",
            "5111808\n",
            "313\n",
            "3855245\n",
            "5128192\n",
            "314\n",
            "3867941\n",
            "5144576\n",
            "315\n",
            "3881279\n",
            "5160960\n",
            "316\n",
            "3894279\n",
            "5177344\n",
            "317\n",
            "3906107\n",
            "5193728\n",
            "318\n",
            "3918065\n",
            "5210112\n",
            "319\n",
            "3931140\n",
            "5226496\n",
            "320\n",
            "3943249\n",
            "5242880\n",
            "321\n",
            "3953419\n",
            "5259264\n",
            "322\n",
            "3967374\n",
            "5275648\n",
            "323\n",
            "3981555\n",
            "5292032\n",
            "324\n",
            "3993783\n",
            "5308416\n",
            "325\n",
            "4006010\n",
            "5324800\n",
            "326\n",
            "4018867\n",
            "5341184\n",
            "327\n",
            "4031832\n",
            "5357568\n",
            "328\n",
            "4041522\n",
            "5373952\n",
            "329\n",
            "4054273\n",
            "5390336\n",
            "330\n",
            "4066368\n",
            "5406720\n",
            "331\n",
            "4079864\n",
            "5423104\n",
            "332\n",
            "4092179\n",
            "5439488\n",
            "333\n",
            "4104707\n",
            "5455872\n",
            "334\n",
            "4117539\n",
            "5472256\n",
            "335\n",
            "4126363\n",
            "5488640\n",
            "336\n",
            "4138357\n",
            "5505024\n",
            "337\n",
            "4151716\n",
            "5521408\n",
            "338\n",
            "4164282\n",
            "5537792\n",
            "339\n",
            "4175851\n",
            "5554176\n",
            "340\n",
            "4189597\n",
            "5570560\n",
            "341\n",
            "4203114\n",
            "5586944\n",
            "342\n",
            "4215561\n",
            "5603328\n",
            "343\n",
            "4228031\n",
            "5619712\n",
            "344\n",
            "4241505\n",
            "5636096\n",
            "345\n",
            "4251973\n",
            "5652480\n",
            "346\n",
            "4264912\n",
            "5668864\n",
            "347\n",
            "4277745\n",
            "5685248\n",
            "348\n",
            "4290180\n",
            "5701632\n",
            "349\n",
            "4302333\n",
            "5718016\n",
            "350\n",
            "4315670\n",
            "5734400\n",
            "351\n",
            "4327682\n",
            "5750784\n",
            "352\n",
            "4340648\n",
            "5767168\n",
            "353\n",
            "4352770\n",
            "5783552\n",
            "354\n",
            "4365605\n",
            "5799936\n",
            "355\n",
            "4377091\n",
            "5816320\n",
            "356\n",
            "4386142\n",
            "5832704\n",
            "357\n",
            "4397564\n",
            "5849088\n",
            "358\n",
            "4409254\n",
            "5865472\n",
            "359\n",
            "4422439\n",
            "5881856\n",
            "360\n",
            "4435044\n",
            "5898240\n",
            "361\n",
            "4447467\n",
            "5914624\n",
            "362\n",
            "4459069\n",
            "5931008\n",
            "363\n",
            "4470791\n",
            "5947392\n",
            "364\n",
            "4482595\n",
            "5963776\n",
            "365\n",
            "4496038\n",
            "5980160\n",
            "366\n",
            "4510043\n",
            "5996544\n",
            "367\n",
            "4521896\n",
            "6012928\n",
            "368\n",
            "4534765\n",
            "6029312\n",
            "369\n",
            "4547055\n",
            "6045696\n",
            "370\n",
            "4558963\n",
            "6062080\n",
            "371\n",
            "4570838\n",
            "6078464\n",
            "372\n",
            "4584453\n",
            "6094848\n",
            "373\n",
            "4597803\n",
            "6111232\n",
            "374\n",
            "4611244\n",
            "6127616\n",
            "375\n",
            "4625073\n",
            "6144000\n",
            "376\n",
            "4636759\n",
            "6160384\n",
            "377\n",
            "4650192\n",
            "6176768\n",
            "378\n",
            "4663366\n",
            "6193152\n",
            "379\n",
            "4674845\n",
            "6209536\n",
            "380\n",
            "4687677\n",
            "6225920\n",
            "381\n",
            "4697824\n",
            "6242304\n",
            "382\n",
            "4710863\n",
            "6258688\n",
            "383\n",
            "4722496\n",
            "6275072\n",
            "384\n",
            "4734543\n",
            "6291456\n",
            "385\n",
            "4745885\n",
            "6307840\n",
            "386\n",
            "4759930\n",
            "6324224\n",
            "387\n",
            "4771113\n",
            "6340608\n",
            "388\n",
            "4783314\n",
            "6356992\n",
            "389\n",
            "4797274\n",
            "6373376\n",
            "390\n",
            "4809861\n",
            "6389760\n",
            "391\n",
            "4821844\n",
            "6406144\n",
            "392\n",
            "4833894\n",
            "6422528\n",
            "393\n",
            "4845489\n",
            "6438912\n",
            "394\n",
            "4859006\n",
            "6455296\n",
            "395\n",
            "4872426\n",
            "6471680\n",
            "396\n",
            "4885174\n",
            "6488064\n",
            "397\n",
            "4898062\n",
            "6504448\n",
            "398\n",
            "4906876\n",
            "6520832\n",
            "399\n",
            "4919538\n",
            "6537216\n",
            "400\n",
            "4932397\n",
            "6553600\n",
            "401\n",
            "4944283\n",
            "6569984\n",
            "402\n",
            "4957837\n",
            "6586368\n",
            "403\n",
            "4971117\n",
            "6602752\n",
            "404\n",
            "4983965\n",
            "6619136\n",
            "405\n",
            "4996512\n",
            "6635520\n",
            "406\n",
            "5008718\n",
            "6651904\n",
            "407\n",
            "5018439\n",
            "6668288\n",
            "408\n",
            "5029830\n",
            "6684672\n",
            "409\n",
            "5041378\n",
            "6701056\n",
            "410\n",
            "5055089\n",
            "6717440\n",
            "411\n",
            "5066601\n",
            "6733824\n",
            "412\n",
            "5079723\n",
            "6750208\n",
            "413\n",
            "5092169\n",
            "6766592\n",
            "414\n",
            "5104809\n",
            "6782976\n",
            "415\n",
            "5117123\n",
            "6799360\n",
            "416\n",
            "5128500\n",
            "6815744\n",
            "417\n",
            "5140230\n",
            "6832128\n",
            "418\n",
            "5153280\n",
            "6848512\n",
            "419\n",
            "5166560\n",
            "6864896\n",
            "420\n",
            "5178869\n",
            "6881280\n",
            "Hence, the test set accuracy is  75.26256715316954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-02MIDT0fN4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5e4e9d35-a043-49b7-d022-8cf6fc679b04"
      },
      "source": [
        "# Converting back to colored form\n",
        "\n",
        "colors = [];\n",
        "colors.append(np.array([64, 128, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 0, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 128, 0], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 128, 0], dtype = 'uint8'));\n",
        "colors.append(np.array([0, 0, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 0, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 0, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 128, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 192, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 64, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 0, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 0, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 128, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 0, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 64, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 192, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([0, 64, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 64, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 128, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 0, 0], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 128, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 128, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 128, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 0, 0], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 64, 0], dtype = 'uint8'));\n",
        "colors.append(np.array([128, 64, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([0, 128, 128], dtype = 'uint8'));\n",
        "colors.append(np.array([192, 128, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([64, 0, 64], dtype = 'uint8'));\n",
        "colors.append(np.array([0, 192, 192], dtype = 'uint8'));\n",
        "colors.append(np.array([0, 0, 0], dtype = 'uint8'))\n",
        "colors.append(np.array([0, 192, 64], dtype = 'uint8'));\n",
        "\n",
        "def test(op_img):\n",
        "    class_pix = np.ones([128, 128, 3], dtype = 'uint8');\n",
        "    for index, c in enumerate(colors):\n",
        "        class_pix[op_img == index] = c; # Vectorized masking is much much faster\n",
        "    return class_pix.reshape((128, 128, 3))\n",
        "\n",
        "print(labels[0]);\n",
        "print(outputs[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[26 26 26 ... 21 21 21]\n",
            " [26 26 26 ... 21 21 21]\n",
            " [26 26 26 ... 21 21 21]\n",
            " ...\n",
            " [19 19 19 ... 17 17 17]\n",
            " [19 19 19 ... 17 17 17]\n",
            " [19 19 19 ... 17 17 17]]\n",
            "[[26 26 26 ... 21 21 21]\n",
            " [26 26 26 ... 21 21 21]\n",
            " [26 26 26 ... 21 21 21]\n",
            " ...\n",
            " [19 19 19 ... 17 17 17]\n",
            " [19 19 19 ... 17 17 17]\n",
            " [19 19 19 ... 17 17 17]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQ1L9whSZjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "821041a6-8acc-46a4-8632-852ac3cfc8ab"
      },
      "source": [
        "print(np.shape(outputs))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVbtnxZ93JH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "81e5f8ae-e52e-4e1b-ffd8-9453649e4445"
      },
      "source": [
        "print(type(test(outputs[0])));\n",
        "a = test(outputs[0]);               # returns reshaped array (128,128,3)\n",
        "# a = a.reshape([128, 128, 3])    \n",
        "print(a.shape)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(a)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAFKUlEQVR4nO2cW3bjIAxAlTldGEvT\n0ljafDiHYGwwDz3A6H7MtGkCri4SBnP6QYQhwsdHG9qUf2QtmYAuRgW4XwoYPRBkwM+BJUE7NCXI\n8qAbujnA6IJagFWhRsgEWBXqY0iAs/E+zJAAbwKGYZiEzUoLowIsCQYhyABzMALLOsAhR6vvhEaA\nJUE39BlgC4ImyAQkSWBVqBLbC1Lmj7AtKz4dcGWAR6aG34aVIGVMgDIsAqz+1GMZoAzlXZDRBiLQ\nZsCxFrP68wxi2LS3EiTOecvABMhy2bX8MOxj0rfIR9izkqicd7HedxJOtguvu4cyk9mmJahms9Yh\n6Z5uptRsJ6A1rDQO8oV+LwF90WR9trHRHFATx9tnqw7R4cCUULzP2UXAY/QLj7WjHz210s4uAnI0\nHifA6N/H91a9jUMALrEUGDjJgXA5F5sWqOrGd8wAkkM0oZHDRFzifMv441gJH3C120e04sXC22ho\n6WGL21DR6MMsApCt5U5Ej+9Vd7VFBoDK4cm6DlkF1F0CPzMfXeXOAGRuvwacuWeBEoT8XUzb+zMy\ncwDOHwgu8OHn756EUfsCAODhKiQFoGBf8t0VwexPhDMAZbubCbx/Wb4E4Yt6aQRvXlOZA1Cj0znA\n9IVXTsKofQFF8PSdlgBU6nc6FDMAl2qWC90ShMvFiwb8fan/ROz0LAlz76ptarmz2fqTcLxVeZya\nmvD0Dj34/V9fANxtF+ucX9NgCgGQPRFVe4hzSRBgHgEFCvG9Glrsr6gh46mINioDF+bYkZNuU6Ev\ngHvMzmsCAToEeI8A4IbrrkqtmEIGnr77jIcSqn1MVaAnOaVCI+CmR8/RKi+VSsIwQtfQuMssEbkE\nxKwoI9AU5RoSExICDpbQQB7uAocJOQEwpQPJiN+ywEKMD/Xow+4CvH5Sym1HU/2q3gEAOKLW4Hxh\n8jmh/zygiSP6xxeEDgLyMoQmYZLhH6KfwGEiwK2BX8Bv2TLUUS76CUwy+DQwCzivLRMHDlz42oMv\nNFMZ/V/Lpcb64dDANgcUl/Vx6ONXbjW0Rh8YJuoD9PQOeDIgH33/FJXEQUf0E1jmakfWFMM6YCD6\nkNQll31bPd7RtBPzXUBQ7KdSZ8BY9OGcAbSB47tZwmSns0UMqYDh6EMkgHzYHshp+L5692J0X04n\ngCL6wC/ggHXpEIiV5O7Cie6CiKIvBtNtUkLN0mdYAM+DPdbhn/SiO0LGBDxFf87hn9Ck4bqCeW6/\nuMbsFVAx8JeIfuBxd68j9LkPxkr+wENby5yHCcqDhRuxihSUePAtd0Etoe8b/ocAmQmgQOHau/Mg\nR10Jahz1I9GfgTACrr+HB0/roEKASPSjj498mpjbi0HwAIBEF/rJhguxo9yPRH+S+tPKoIm8gHZG\nxz745aIf6NZAI2D8jnPR4Z/QoYFgO5rqfn/16AMAtodiVMBaqy0BWh0MCSAb+ytX/ytNDvoF2Ngv\ngM5XatA/mjjP+oucGgedAmiH/5vqT8JjKvTchhJG/x13n/Vc71ObM4A8+ltxTYg2ATbxkhBrqC1B\n5KGXefg+P8+7oTbqWSkJ4Av9htU/RyrAxrswXwFacd98AoDjLkg4+lZ/Yv5ZzdFFcy/I6g/IC7D6\nk6CWATb8D/S3ozdHVIBtP1xRyACLfoycAJt+bxESYMUnh+wc4CR7WwMJAVZ8CrALsOJTxtYBykhN\nwk6mn/Xg/YtZLztzyAFvBlj0H2EU0HFWe0O4BFj0K7G7IGVYBNjwr4degEW/if+ZIK3oXUHFMQAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7FDF60CDBEB8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}